{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os, yaml, zipfile, shutil, torch, glob\n",
        "from ultralytics import YOLO\n",
        "from IPython.display import Image, display\n",
        "from utils.create_data_yaml import create_data_yaml_from_set_and_classes\n",
        "from utils.get_notebook_path import get_notebook_path\n",
        "from utils.clear_folder import clear_folder\n",
        "from utils.data_cleaning import data_cleaning\n",
        "from utils.preview_labels import preview_labels\n",
        "from utils.analyze_imgsz import analyze_imgsz\n",
        "from utils.data_preprocess import data_preprocess"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1sUfcA8ZgR2t"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "This notebook uses [Ultralytics](https://docs.ultralytics.com/) to train YOLO11, YOLOv8, or YOLOv5 object detection models with a custom dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NW7LLv_QPOO"
      },
      "source": [
        "**Verify NVIDIA GPU Availability**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfaWho47RGDf",
        "outputId": "3939810c-b265-4c66-d2d3-2e512309453f"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPZEM27IOh79"
      },
      "source": [
        "**Option 1. Upload the Dataset**\n",
        "\n",
        "Upload the `data.zip` (Export from Label studio) to the root folder."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7Iz9eBzW5zm"
      },
      "source": [
        "## 2. Split images into train and validation folders\n",
        "Next, we'll unzip `data.zip` and create some folders to hold the images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z8O6z-wVcPEF"
      },
      "outputs": [],
      "source": [
        "# Extract custom_data (required)\n",
        "extract_dir = \"dataset/custom_data\"\n",
        "zip_path = \"dataset/data.zip\"\n",
        "\n",
        "clear_folder(extract_dir)\n",
        "\n",
        "if os.path.exists(zip_path):\n",
        "    clear_folder(extract_dir)\n",
        "    os.makedirs(extract_dir, exist_ok=True)\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_dir)\n",
        "else:\n",
        "    print(\"dataset/set.zip not found; skipping set extraction.\")\n",
        "\n",
        "# Extract set (optional)\n",
        "set_extract_dir = \"dataset/set\"\n",
        "set_zip_path = \"dataset/set.zip\"\n",
        "\n",
        "if os.path.exists(set_zip_path):\n",
        "    clear_folder(set_extract_dir)\n",
        "    os.makedirs(set_extract_dir, exist_ok=True)\n",
        "    with zipfile.ZipFile(set_zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(set_extract_dir)\n",
        "else:\n",
        "    print(\"dataset/set.zip not found; skipping set extraction.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eoPjqW6AYebn"
      },
      "source": [
        "Now we will build the Ultralytics folder structure under `data/` by merging:\n",
        "\n",
        "- `dataset/set/` (from `set.zip`): copy `train` and `valid` (and optionally `test`) into `data/`.\n",
        "- `dataset/custom_data/`: split 80/20 (configurable) and append into `data/train` and `data/validation`.\n",
        "\n",
        "The script avoids filename collisions and pairs each image with its corresponding label."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8X62eFTugosf"
      },
      "outputs": [],
      "source": [
        "clear_folder(\"data\")\n",
        "!python -m utils.merge_datasets --set_dir dataset/set --custom_dir dataset/custom_data --data_dir data --train_pct 0.9 --include_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuZoMkSFN9XG"
      },
      "source": [
        "# 4.&nbsp;Configure Training\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0c5Kdh0GmQHS"
      },
      "source": [
        "There's one last step before training: create `data.yaml`. We'll take the class names (`names` and `nc`) directly from `dataset/set/data.yaml`, and point `train`/`val` to our merged `data/` folders."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4letvP7X12ji"
      },
      "outputs": [],
      "source": [
        "path_to_set_yaml = 'dataset/set/data.yaml'\n",
        "path_to_classes_txt = 'dataset/custom_data/classes.txt'\n",
        "path_to_data_yaml = 'data.yaml'\n",
        "\n",
        "create_data_yaml_from_set_and_classes(path_to_set_yaml, path_to_classes_txt, path_to_data_yaml)\n",
        "\n",
        "print('\\nFile contents:\\n')\n",
        "with open(\"data.yaml\", \"r\") as f:\n",
        "    print(f.read())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myP80_bnTNMi"
      },
      "source": [
        "# 5.&nbsp;Train Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DfKspYasCzC8"
      },
      "source": [
        "## 5.1 Training Parameters\n",
        "\n",
        "**Model architecture & size (`model`):**\n",
        "\n",
        "There are several YOLO11 models sizes available to train, including `yolo11n.pt`, `yolo11s.pt`, `yolo11m.pt`, `yolo11l.pt`, and `yolo11xl.pt`. Larger models run slower but have higher accuracy, while smaller models run faster but have lower accuracy. \n",
        "\n",
        "Example: [check it out here to get a sense of their speed accuracy](https://youtu.be/_WKS4E9SmkA). \n",
        "By default, `yolo11s.pt` will be used as the starting point.\n",
        "\n",
        "We can also train with YOLOv8 or YOLOv5 models by substituting `yolo11` for `yolov8` or `yolov5`.\n",
        "\n",
        "\n",
        "**Number of epochs (`epochs`)**\n",
        "In machine learning, one “epoch” is one single pass through the full training dataset. Setting the number of epochs dictates how long the model will train for. The best amount of epochs to use depends on the size of the dataset and the model architecture. \n",
        "\n",
        "In our case we will use 60 epochs. \n",
        "If your dataset has more than 200 images, a good starting point is 40 epochs.\n",
        "\n",
        "\n",
        "**Resolution (`imgsz`)**\n",
        "Resolution has a large impact on the speed and accuracy of the model: a lower resolution model will have higher speed but less accuracy. \n",
        "YOLO models are typically trained and inferenced at a 640x640 resolution. \n",
        "\n",
        "We can choose to lower the resolution to 480x480 for better model performance\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQi_hXnUVPr-"
      },
      "source": [
        "model = Specifies the model to use\n",
        "epochs = Specifies the number of training epochs\n",
        "imgsz = Specifies the resolution of the images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(torch.cuda.is_available())\n",
        "print(torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU detectada\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_cleaning()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "clear_folder(\"previews/\")\n",
        "preview_labels(data_path=\"data\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "analyze_imgsz()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "PREPROCESSED_DATA_FOLDER = \"data_preprocessed\"\n",
        "\n",
        "clear_folder(PREPROCESSED_DATA_FOLDER)\n",
        "data_preprocess(datap_path=PREPROCESSED_DATA_FOLDER)\n",
        "preview_labels(data_path=PREPROCESSED_DATA_FOLDER)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8bbpob1gTPlo"
      },
      "outputs": [],
      "source": [
        "clear_folder(\"runs/detect/train\")\n",
        "\n",
        "model = YOLO(\"yolo11s.pt\")\n",
        "\n",
        "model.train(\n",
        "    data=\"data.yaml\",\n",
        "    model=\"yolo11s.pt\",\n",
        "    epochs=60,\n",
        "    imgsz=512,\n",
        "    batch=16,\n",
        "    workers=8,\n",
        "    amp=True,\n",
        "\n",
        "    # AUGMENTATION — VALIDADO PARA YOLO11\n",
        "    hsv_h=0.015,       # variación ligera de tono\n",
        "    hsv_s=0.7,         # saturación fuerte (útil en exteriores)\n",
        "    hsv_v=0.4,         # variación de brillo moderada\n",
        "    degrees=5.0,       # rotación suave (personas no deben rotarse mucho)\n",
        "    translate=0.10,    # desplazamiento leve\n",
        "    scale=0.50,        # zoom in/out moderado\n",
        "    shear=1.5,         # deformación suave\n",
        "    perspective=0.0005,# perspectiva muy ligera\n",
        "    flipud=0.0,        # NO voltear verticalmente personas\n",
        "    fliplr=0.5,        # flip horizontal sí es natural\n",
        "    mosaic=1.0,        # mosaico activado (muy útil)\n",
        "    mixup=0.10,        # mezcla suave\n",
        "    copy_paste=0.0,    # no recomendado para humanos\n",
        "    erasing=0.4,       # borrado aleatorio útil, sin exagerar\n",
        "    crop_fraction=1.0, # 1.0 = sin recorte agresivo\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vv0EYWJ5V6mC"
      },
      "source": [
        "The training algorithm will parse the images in the training and validation directories and then start training the model. \n",
        "\n",
        "At the end of each training epoch, the program runs the model on the validation dataset and reports the resulting mAP, precision, and recall. As training continues, the mAP should generally increase with each epoch. Training will end once it goes through the number of epochs specified.\n",
        "\n",
        "The best trained model weights will be saved in `content/runs/detect/train/weights/best.pt`. Additional information about training is saved in the `content/runs/detect/train` folder, including a `results.png` file that shows how loss, precision, recall, and mAP progressed over each epoch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 6.&nbsp;Test Model\n",
        "The commands below run the model on the images in the validation folder and then display the results for the first 10 images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PooP5Vjsg2Jn"
      },
      "outputs": [],
      "source": [
        "clear_folder(\"runs/detect/predict\")\n",
        "\n",
        "model = YOLO(\"runs/detect/train3/weights/best.pt\")\n",
        "\n",
        "results = model.predict(\n",
        "    source=\"data/validation/images\",  \n",
        "    save=True,\n",
        "    show=False,\n",
        "    conf=0.25\n",
        ")\n",
        "\n",
        "for image_path in glob.glob(f'runs/detect/predict/*.jpg')[:5]:\n",
        "  display(Image(filename=image_path, height=400))\n",
        "  print('\\n')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGiQw_gWbSBa"
      },
      "source": [
        "The model should draw a box around each object of interest in each image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7yrFRViVczX"
      },
      "source": [
        "# 7.&nbsp;Deploy Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IcoBAeHXa86W"
      },
      "source": [
        "## 7.1 Download YOLO Model\n",
        "\n",
        "First, zip and download the trained model by running the code blocks below.\n",
        "\n",
        "The code creates a folder named `my_model`, moves the model weights into it, and renames them from `best.pt` to `my_model.pt`, and also adds the training results for reference."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qcBdnOA9v85S"
      },
      "outputs": [],
      "source": [
        "#clear_folder(\"my_model\")\n",
        "\n",
        "base_dir = get_notebook_path()\n",
        "train_dir = os.path.join(base_dir, \"runs\", \"detect\", \"train3\")\n",
        "output_dir = os.path.join(base_dir, \"my_model\")\n",
        "\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "shutil.copy(os.path.join(train_dir, \"weights\", \"best.pt\"), os.path.join(output_dir, \"my_model.pt\"))\n",
        "shutil.copytree(train_dir, os.path.join(output_dir, \"train\"), dirs_exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 8. Using the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python utils/yolo_detect.py --model my_model/my_model.pt --source usb1 --resolution 1280x720"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python utils/yolo_detect.py --model my_model/persons_model.pt --source usb1 --resolution 1280x720"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python utils/yolo_detect.py --model my_model/full_model.pt --source usb1 --resolution 1280x720"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "train-model-env1",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
